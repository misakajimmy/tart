{"version":3,"sources":["common/stream.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;kFAckF;AAelF,MAAM,WAAW,oBAAoB,CAAC,CAAC;IAErC;;;OAGG;IACH,EAAE,CAAC,KAAK,EAAE,MAAM,EAAE,QAAQ,EAAE,CAAC,IAAI,EAAE,CAAC,KAAK,IAAI,GAAG,IAAI,CAAC;IAErD;;OAEG;IACH,EAAE,CAAC,KAAK,EAAE,OAAO,EAAE,QAAQ,EAAE,CAAC,GAAG,EAAE,KAAK,KAAK,IAAI,GAAG,IAAI,CAAC;IAEzD;;;;OAIG;IACH,EAAE,CAAC,KAAK,EAAE,KAAK,EAAE,QAAQ,EAAE,MAAM,IAAI,GAAG,IAAI,CAAC;CAC9C;AAED;;;GAGG;AACH,MAAM,WAAW,cAAc,CAAC,CAAC,CAAE,SAAQ,oBAAoB,CAAC,CAAC,CAAC;IAEhE;;OAEG;IACH,KAAK,IAAI,IAAI,CAAC;IAEd;;OAEG;IACH,MAAM,IAAI,IAAI,CAAC;IAEf;;OAEG;IACH,OAAO,IAAI,IAAI,CAAC;IAEhB;;OAEG;IACH,cAAc,CAAC,KAAK,EAAE,MAAM,EAAE,QAAQ,EAAE,QAAQ,GAAG,IAAI,CAAC;CACzD;AAED;;;GAGG;AACH,MAAM,WAAW,QAAQ,CAAC,CAAC;IAEzB;;;OAGG;IACH,IAAI,IAAI,CAAC,GAAG,IAAI,CAAC;CAClB;AAED,yBAAiB,QAAQ,CAAC;IACxB,SAAgB,UAAU,CAAC,KAAK,EAAE,MAAM,GAAG,QAAQ,CAAC,MAAM,CAAC,CAc1D;IAED,SAAgB,QAAQ,CAAC,QAAQ,EAAE,QAAQ,CAAC,MAAM,CAAC,GAAG,MAAM,CAO3D;CACF;AAED;;;GAGG;AACH,MAAM,WAAW,eAAe,CAAC,CAAC,CAAE,SAAQ,cAAc,CAAC,CAAC,CAAC;IAE3D;;;;;;;;;;OAUG;IACH,KAAK,CAAC,IAAI,EAAE,CAAC,GAAG,IAAI,GAAG,OAAO,CAAC,IAAI,CAAC,CAAC;IAErC;;;OAGG;IACH,KAAK,CAAC,KAAK,EAAE,KAAK,GAAG,IAAI,CAAC;IAE1B;;;;;;;;OAQG;IACH,GAAG,CAAC,MAAM,CAAC,EAAE,CAAC,GAAG,KAAK,GAAG,IAAI,CAAC;CAC/B;AAED;;;;;GAKG;AACH,MAAM,WAAW,sBAAsB,CAAC,CAAC;IAEvC;;OAEG;IACH,MAAM,EAAE,cAAc,CAAC,CAAC,CAAC,CAAC;IAE1B;;OAEG;IACH,MAAM,EAAE,CAAC,EAAE,CAAC;IAEZ;;;OAGG;IACH,KAAK,EAAE,OAAO,CAAC;CAChB;AAED,wBAAgB,gBAAgB,CAAC,CAAC,EAAE,GAAG,EAAE,OAAO,GAAG,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,CAI1E;AAED,wBAAgB,wBAAwB,CAAC,CAAC,EAAE,GAAG,EAAE,OAAO,GAAG,GAAG,IAAI,sBAAsB,CAAC,CAAC,CAAC,CAI1F;AAED,MAAM,WAAW,OAAO,CAAC,CAAC;IACxB,CAAC,IAAI,EAAE,CAAC,EAAE,GAAG,CAAC,CAAC;CAChB;AAED,MAAM,WAAW,eAAe,CAAC,QAAQ,EAAE,WAAW;IACpD,CAAC,IAAI,EAAE,QAAQ,GAAG,WAAW,CAAC;CAC/B;AAED,MAAM,WAAW,gBAAgB;IAC/B,CAAC,KAAK,EAAE,KAAK,GAAG,KAAK,CAAC;CACvB;AAED,MAAM,WAAW,YAAY,CAAC,QAAQ,EAAE,WAAW;IACjD,IAAI,EAAE,eAAe,CAAC,QAAQ,EAAE,WAAW,CAAC,CAAC;IAC7C,KAAK,CAAC,EAAE,gBAAgB,CAAC;CAC1B;AAED,wBAAgB,kBAAkB,CAAC,CAAC,EAAE,OAAO,EAAE,OAAO,CAAC,CAAC,CAAC,EAAE,OAAO,CAAC,EAAE,sBAAsB,GAAG,eAAe,CAAC,CAAC,CAAC,CAE/G;AAED,MAAM,WAAW,sBAAsB;IAErC;;;;OAIG;IACH,aAAa,CAAC,EAAE,MAAM,CAAC;CACxB;AA4OD;;GAEG;AACH,wBAAgB,eAAe,CAAC,CAAC,EAAE,QAAQ,EAAE,QAAQ,CAAC,CAAC,CAAC,EAAE,OAAO,EAAE,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC,CAShF;AAED;;;;GAIG;AACH,wBAAgB,wBAAwB,CAAC,CAAC,EAAE,QAAQ,EAAE,QAAQ,CAAC,CAAC,CAAC,EAAE,OAAO,EAAE,OAAO,CAAC,CAAC,CAAC,EAAE,SAAS,EAAE,MAAM,GAAG,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAyC1H;AAED;;;;GAIG;AACH,wBAAgB,YAAY,CAAC,CAAC,EAAE,QAAQ,EAAE,QAAQ,CAAC,CAAC,CAAC,EAAE,OAAO,EAAE,OAAO,CAAC,CAAC,CAAC,EAAE,SAAS,EAAE,MAAM,GAAG,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAyC9G;AAED;;GAEG;AACH,wBAAgB,aAAa,CAAC,CAAC,EAAE,MAAM,EAAE,cAAc,CAAC,CAAC,CAAC,EAAE,OAAO,EAAE,OAAO,CAAC,CAAC,CAAC,GAAG,OAAO,CAAC,CAAC,CAAC,CAQ3F;AAED;;;;GAIG;AACH,wBAAgB,UAAU,CAAC,CAAC,EAAE,MAAM,EAAE,cAAc,CAAC,CAAC,CAAC,EAAE,SAAS,EAAE,MAAM,GAAG,OAAO,CAAC,sBAAsB,CAAC,CAAC,CAAC,CAAC,CAqC9G;AAED;;;;GAIG;AACH,wBAAgB,sBAAsB,CAAC,CAAC,EAAE,MAAM,EAAE,cAAc,CAAC,CAAC,CAAC,EAAE,OAAO,EAAE,OAAO,CAAC,CAAC,CAAC,EAAE,SAAS,EAAE,MAAM,GAAG,OAAO,CAAC,CAAC,GAAG,cAAc,CAAC,CAAC,CAAC,CAAC,CAiD3I;AAED;;GAEG;AACH,wBAAgB,QAAQ,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,OAAO,EAAE,OAAO,CAAC,CAAC,CAAC,GAAG,cAAc,CAAC,CAAC,CAAC,CAMxE;AAED;;GAEG;AACH,wBAAgB,UAAU,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAc/C;AAED;;GAEG;AACH,wBAAgB,SAAS,CAAC,QAAQ,EAAE,WAAW,EAAE,MAAM,EAAE,oBAAoB,CAAC,QAAQ,CAAC,EAAE,WAAW,EAAE,YAAY,CAAC,QAAQ,EAAE,WAAW,CAAC,EAAE,OAAO,EAAE,OAAO,CAAC,WAAW,CAAC,GAAG,cAAc,CAAC,WAAW,CAAC,CAQrM","file":"../../src/common/stream.d.ts","sourcesContent":["/********************************************************************************\n * Copyright (C) 2020 TypeFox and others.\n *\n * This program and the accompanying materials are made available under the\n * terms of the Eclipse Public License v. 2.0 which is available at\n * http://www.eclipse.org/legal/epl-2.0.\n *\n * This Source Code may also be made available under the following Secondary\n * Licenses when the conditions for such availability set forth in the Eclipse\n * Public License v. 2.0 are satisfied: GNU General Public License, version 2\n * with the GNU Classpath Exception which is available at\n * https://www.gnu.org/software/classpath/license.html.\n *\n * SPDX-License-Identifier: EPL-2.0 OR GPL-2.0 WITH Classpath-exception-2.0\n ********************************************************************************/\n/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\n// based on https://github.com/microsoft/vscode/blob/04c36be045a94fee58e5f8992d3e3fd980294a84/src/vs/base/common/stream.ts\n\n/* eslint-disable max-len */\n/* eslint-disable no-null/no-null */\n/* eslint-disable @typescript-eslint/tslint/config */\n/* eslint-disable @typescript-eslint/no-explicit-any */\n\nimport {Disposable, DisposableCollection} from './disposable';\n\nexport interface ReadableStreamEvents<T> {\n\n  /**\n   * The 'data' event is emitted whenever the stream is\n   * relinquishing ownership of a chunk of data to a consumer.\n   */\n  on(event: 'data', callback: (data: T) => void): void;\n\n  /**\n   * Emitted when any error occurs.\n   */\n  on(event: 'error', callback: (err: Error) => void): void;\n\n  /**\n   * The 'end' event is emitted when there is no more data\n   * to be consumed from the stream. The 'end' event will\n   * not be emitted unless the data is completely consumed.\n   */\n  on(event: 'end', callback: () => void): void;\n}\n\n/**\n * A interface that emulates the API shape of a node.js readable\n * stream for use in desktop and web environments.\n */\nexport interface ReadableStream<T> extends ReadableStreamEvents<T> {\n\n  /**\n   * Stops emitting any events until resume() is called.\n   */\n  pause(): void;\n\n  /**\n   * Starts emitting events again after pause() was called.\n   */\n  resume(): void;\n\n  /**\n   * Destroys the stream and stops emitting any event.\n   */\n  destroy(): void;\n\n  /**\n   * Allows to remove a listener that was previously added.\n   */\n  removeListener(event: string, callback: Function): void;\n}\n\n/**\n * A interface that emulates the API shape of a node.js readable\n * for use in desktop and web environments.\n */\nexport interface Readable<T> {\n\n  /**\n   * Read data from the underlying source. Will return\n   * null to indicate that no more data can be read.\n   */\n  read(): T | null;\n}\n\nexport namespace Readable {\n  export function fromString(value: string): Readable<string> {\n    let done = false;\n\n    return {\n      read(): string | null {\n        if (!done) {\n          done = true;\n\n          return value;\n        }\n\n        return null;\n      }\n    };\n  }\n\n  export function toString(readable: Readable<string>): string {\n    let result = '';\n    let chunk: string | null;\n    while ((chunk = readable.read()) != null) {\n      result += chunk;\n    }\n    return result;\n  }\n}\n\n/**\n * A interface that emulates the API shape of a node.js writeable\n * stream for use in desktop and web environments.\n */\nexport interface WriteableStream<T> extends ReadableStream<T> {\n\n  /**\n   * Writing data to the stream will trigger the on('data')\n   * event listener if the stream is flowing and buffer the\n   * data otherwise until the stream is flowing.\n   *\n   * If a `highWaterMark` is configured and writing to the\n   * stream reaches this mark, a promise will be returned\n   * that should be awaited on before writing more data.\n   * Otherwise there is a risk of buffering a large number\n   * of data chunks without consumer.\n   */\n  write(data: T): void | Promise<void>;\n\n  /**\n   * Signals an error to the consumer of the stream via the\n   * on('error') handler if the stream is flowing.\n   */\n  error(error: Error): void;\n\n  /**\n   * Signals the end of the stream to the consumer. If the\n   * result is not an error, will trigger the on('data') event\n   * listener if the stream is flowing and buffer the data\n   * otherwise until the stream is flowing.\n   *\n   * In case of an error, the on('error') event will be used\n   * if the stream is flowing.\n   */\n  end(result?: T | Error): void;\n}\n\n/**\n * A stream that has a buffer already read. Returns the original stream\n * that was read as well as the chunks that got read.\n *\n * The `ended` flag indicates if the stream has been fully consumed.\n */\nexport interface ReadableBufferedStream<T> {\n\n  /**\n   * The original stream that is being read.\n   */\n  stream: ReadableStream<T>;\n\n  /**\n   * An array of chunks already read from this stream.\n   */\n  buffer: T[];\n\n  /**\n   * Signals if the stream has ended or not. If not, consumers\n   * should continue to read from the stream until consumed.\n   */\n  ended: boolean;\n}\n\nexport function isReadableStream<T>(obj: unknown): obj is ReadableStream<T> {\n  const candidate = obj as ReadableStream<T>;\n\n  return candidate && [candidate.on, candidate.pause, candidate.resume, candidate.destroy].every(fn => typeof fn === 'function');\n}\n\nexport function isReadableBufferedStream<T>(obj: unknown): obj is ReadableBufferedStream<T> {\n  const candidate = obj as ReadableBufferedStream<T>;\n\n  return candidate && isReadableStream(candidate.stream) && Array.isArray(candidate.buffer) && typeof candidate.ended === 'boolean';\n}\n\nexport interface Reducer<T> {\n  (data: T[]): T;\n}\n\nexport interface DataTransformer<Original, Transformed> {\n  (data: Original): Transformed;\n}\n\nexport interface ErrorTransformer {\n  (error: Error): Error;\n}\n\nexport interface ITransformer<Original, Transformed> {\n  data: DataTransformer<Original, Transformed>;\n  error?: ErrorTransformer;\n}\n\nexport function newWriteableStream<T>(reducer: Reducer<T>, options?: WriteableStreamOptions): WriteableStream<T> {\n  return new WriteableStreamImpl<T>(reducer);\n}\n\nexport interface WriteableStreamOptions {\n\n  /**\n   * The number of objects to buffer before WriteableStream#write()\n   * signals back that the buffer is full. Can be used to reduce\n   * the memory pressure when the stream is not flowing.\n   */\n  highWaterMark?: number;\n}\n\nclass WriteableStreamImpl<T> implements WriteableStream<T> {\n\n  private readonly state = {\n    flowing: false,\n    ended: false,\n    destroyed: false\n  };\n\n  private readonly buffer = {\n    data: [] as T[],\n    error: [] as Error[]\n  };\n\n  private readonly listeners = {\n    data: [] as { (data: T): void }[],\n    error: [] as { (error: Error): void }[],\n    end: [] as { (): void }[]\n  };\n\n  private readonly pendingWritePromises: Function[] = [];\n\n  constructor(private reducer: Reducer<T>, private options?: WriteableStreamOptions) {\n  }\n\n  pause(): void {\n    if (this.state.destroyed) {\n      return;\n    }\n\n    this.state.flowing = false;\n  }\n\n  resume(): void {\n    if (this.state.destroyed) {\n      return;\n    }\n\n    if (!this.state.flowing) {\n      this.state.flowing = true;\n\n      // emit buffered events\n      this.flowData();\n      this.flowErrors();\n      this.flowEnd();\n    }\n  }\n\n  write(data: T): void | Promise<void> {\n    if (this.state.destroyed) {\n      return;\n    }\n\n    // flowing: directly send the data to listeners\n    if (this.state.flowing) {\n      this.listeners.data.forEach(listener => listener(data));\n    }\n\n    // not yet flowing: buffer data until flowing\n    else {\n      this.buffer.data.push(data);\n\n      // highWaterMark: if configured, signal back when buffer reached limits\n      if (typeof this.options?.highWaterMark === 'number' && this.buffer.data.length > this.options.highWaterMark) {\n        return new Promise(resolve => this.pendingWritePromises.push(resolve));\n      }\n    }\n  }\n\n  error(error: Error): void {\n    if (this.state.destroyed) {\n      return;\n    }\n\n    // flowing: directly send the error to listeners\n    if (this.state.flowing) {\n      this.listeners.error.forEach(listener => listener(error));\n    }\n\n    // not yet flowing: buffer errors until flowing\n    else {\n      this.buffer.error.push(error);\n    }\n  }\n\n  end(result?: T | Error): void {\n    if (this.state.destroyed) {\n      return;\n    }\n\n    // end with data or error if provided\n    if (result instanceof Error) {\n      this.error(result);\n    } else if (result) {\n      this.write(result);\n    }\n\n    // flowing: send end event to listeners\n    if (this.state.flowing) {\n      this.listeners.end.forEach(listener => listener());\n\n      this.destroy();\n    }\n\n    // not yet flowing: remember state\n    else {\n      this.state.ended = true;\n    }\n  }\n\n  on(event: 'data', callback: (data: T) => void): void;\n  on(event: 'error', callback: (err: Error) => void): void;\n  on(event: 'end', callback: () => void): void;\n  on(event: 'data' | 'error' | 'end', callback: (arg0?: any) => void): void {\n    if (this.state.destroyed) {\n      return;\n    }\n\n    switch (event) {\n      case 'data':\n        this.listeners.data.push(callback);\n\n        // switch into flowing mode as soon as the first 'data'\n        // listener is added and we are not yet in flowing mode\n        this.resume();\n\n        break;\n\n      case 'end':\n        this.listeners.end.push(callback);\n\n        // emit 'end' event directly if we are flowing\n        // and the end has already been reached\n        //\n        // finish() when it went through\n        if (this.state.flowing && this.flowEnd()) {\n          this.destroy();\n        }\n\n        break;\n\n      case 'error':\n        this.listeners.error.push(callback);\n\n        // emit buffered 'error' events unless done already\n        // now that we know that we have at least one listener\n        if (this.state.flowing) {\n          this.flowErrors();\n        }\n\n        break;\n    }\n  }\n\n  removeListener(event: string, callback: Function): void {\n    if (this.state.destroyed) {\n      return;\n    }\n\n    let listeners: unknown[] | undefined = undefined;\n\n    switch (event) {\n      case 'data':\n        listeners = this.listeners.data;\n        break;\n\n      case 'end':\n        listeners = this.listeners.end;\n        break;\n\n      case 'error':\n        listeners = this.listeners.error;\n        break;\n    }\n\n    if (listeners) {\n      const index = listeners.indexOf(callback);\n      if (index >= 0) {\n        listeners.splice(index, 1);\n      }\n    }\n  }\n\n  destroy(): void {\n    if (!this.state.destroyed) {\n      this.state.destroyed = true;\n      this.state.ended = true;\n\n      this.buffer.data.length = 0;\n      this.buffer.error.length = 0;\n\n      this.listeners.data.length = 0;\n      this.listeners.error.length = 0;\n      this.listeners.end.length = 0;\n\n      this.pendingWritePromises.length = 0;\n    }\n  }\n\n  private flowData(): void {\n    if (this.buffer.data.length > 0) {\n      const fullDataBuffer = this.reducer(this.buffer.data);\n\n      this.listeners.data.forEach(listener => listener(fullDataBuffer));\n\n      this.buffer.data.length = 0;\n\n      // When the buffer is empty, resolve all pending writers\n      const pendingWritePromises = [...this.pendingWritePromises];\n      this.pendingWritePromises.length = 0;\n      pendingWritePromises.forEach(pendingWritePromise => pendingWritePromise());\n    }\n  }\n\n  private flowErrors(): void {\n    if (this.listeners.error.length > 0) {\n      for (const error of this.buffer.error) {\n        this.listeners.error.forEach(listener => listener(error));\n      }\n\n      this.buffer.error.length = 0;\n    }\n  }\n\n  private flowEnd(): boolean {\n    if (this.state.ended) {\n      this.listeners.end.forEach(listener => listener());\n\n      return this.listeners.end.length > 0;\n    }\n\n    return false;\n  }\n}\n\n/**\n * Helper to fully read a T readable into a T.\n */\nexport function consumeReadable<T>(readable: Readable<T>, reducer: Reducer<T>): T {\n  const chunks: T[] = [];\n\n  let chunk: T | null;\n  while ((chunk = readable.read()) !== null) {\n    chunks.push(chunk);\n  }\n\n  return reducer(chunks);\n}\n\n/**\n * Helper to read a T readable up to a maximum of chunks. If the limit is\n * reached, will return a readable instead to ensure all data can still\n * be read.\n */\nexport function consumeReadableWithLimit<T>(readable: Readable<T>, reducer: Reducer<T>, maxChunks: number): T | Readable<T> {\n  const chunks: T[] = [];\n\n  let chunk: T | null | undefined = undefined;\n  while ((chunk = readable.read()) !== null && chunks.length < maxChunks) {\n    chunks.push(chunk);\n  }\n\n  // If the last chunk is null, it means we reached the end of\n  // the readable and return all the data at once\n  if (chunk === null && chunks.length > 0) {\n    return reducer(chunks);\n  }\n\n  // Otherwise, we still have a chunk, it means we reached the maxChunks\n  // value and as such we return a new Readable that first returns\n  // the existing read chunks and then continues with reading from\n  // the underlying readable.\n  return {\n    read: () => {\n\n      // First consume chunks from our array\n      if (chunks.length > 0) {\n        return chunks.shift()!;\n      }\n\n      // Then ensure to return our last read chunk\n      if (typeof chunk !== 'undefined') {\n        const lastReadChunk = chunk;\n\n        // explicitly use undefined here to indicate that we consumed\n        // the chunk, which could have either been null or valued.\n        chunk = undefined;\n\n        return lastReadChunk;\n      }\n\n      // Finally delegate back to the Readable\n      return readable.read();\n    }\n  };\n}\n\n/**\n * Helper to read a T readable up to a maximum of chunks. If the limit is\n * reached, will return a readable instead to ensure all data can still\n * be read.\n */\nexport function peekReadable<T>(readable: Readable<T>, reducer: Reducer<T>, maxChunks: number): T | Readable<T> {\n  const chunks: T[] = [];\n\n  let chunk: T | null | undefined = undefined;\n  while ((chunk = readable.read()) !== null && chunks.length < maxChunks) {\n    chunks.push(chunk);\n  }\n\n  // If the last chunk is null, it means we reached the end of\n  // the readable and return all the data at once\n  if (chunk === null && chunks.length > 0) {\n    return reducer(chunks);\n  }\n\n  // Otherwise, we still have a chunk, it means we reached the maxChunks\n  // value and as such we return a new Readable that first returns\n  // the existing read chunks and then continues with reading from\n  // the underlying readable.\n  return {\n    read: () => {\n\n      // First consume chunks from our array\n      if (chunks.length > 0) {\n        return chunks.shift()!;\n      }\n\n      // Then ensure to return our last read chunk\n      if (typeof chunk !== 'undefined') {\n        const lastReadChunk = chunk;\n\n        // explicitly use undefined here to indicate that we consumed\n        // the chunk, which could have either been null or valued.\n        chunk = undefined;\n\n        return lastReadChunk;\n      }\n\n      // Finally delegate back to the Readable\n      return readable.read();\n    }\n  };\n}\n\n/**\n * Helper to fully read a T stream into a T.\n */\nexport function consumeStream<T>(stream: ReadableStream<T>, reducer: Reducer<T>): Promise<T> {\n  return new Promise((resolve, reject) => {\n    const chunks: T[] = [];\n\n    stream.on('data', data => chunks.push(data));\n    stream.on('error', error => reject(error));\n    stream.on('end', () => resolve(reducer(chunks)));\n  });\n}\n\n/**\n * Helper to peek up to `maxChunks` into a stream. The return type signals if\n * the stream has ended or not. If not, caller needs to add a `data` listener\n * to continue reading.\n */\nexport function peekStream<T>(stream: ReadableStream<T>, maxChunks: number): Promise<ReadableBufferedStream<T>> {\n  return new Promise((resolve, reject) => {\n    const streamListeners = new DisposableCollection();\n\n    // Data Listener\n    const buffer: T[] = [];\n    const dataListener = (chunk: T) => {\n\n      // Add to buffer\n      buffer.push(chunk);\n\n      // We reached maxChunks and thus need to return\n      if (buffer.length > maxChunks) {\n\n        // Dispose any listeners and ensure to pause the\n        // stream so that it can be consumed again by caller\n        streamListeners.dispose();\n        stream.pause();\n\n        return resolve({stream, buffer, ended: false});\n      }\n    };\n\n    streamListeners.push(Disposable.create(() => stream.removeListener('data', dataListener)));\n    stream.on('data', dataListener);\n\n    // Error Listener\n    const errorListener = (error: Error) => reject(error);\n\n    streamListeners.push(Disposable.create(() => stream.removeListener('error', errorListener)));\n    stream.on('error', errorListener);\n\n    const endListener = () => resolve({stream, buffer, ended: true});\n\n    streamListeners.push(Disposable.create(() => stream.removeListener('end', endListener)));\n    stream.on('end', endListener);\n  });\n}\n\n/**\n * Helper to read a T stream up to a maximum of chunks. If the limit is\n * reached, will return a stream instead to ensure all data can still\n * be read.\n */\nexport function consumeStreamWithLimit<T>(stream: ReadableStream<T>, reducer: Reducer<T>, maxChunks: number): Promise<T | ReadableStream<T>> {\n  return new Promise((resolve, reject) => {\n    const chunks: T[] = [];\n\n    let wrapperStream: WriteableStream<T> | undefined = undefined;\n\n    stream.on('data', data => {\n\n      // If we reach maxChunks, we start to return a stream\n      // and make sure that any data we have already read\n      // is in it as well\n      if (!wrapperStream && chunks.length === maxChunks) {\n        wrapperStream = newWriteableStream(reducer);\n        while (chunks.length) {\n          wrapperStream.write(chunks.shift()!);\n        }\n\n        wrapperStream.write(data);\n\n        return resolve(wrapperStream);\n      }\n\n      if (wrapperStream) {\n        wrapperStream.write(data);\n      } else {\n        chunks.push(data);\n      }\n    });\n\n    stream.on('error', error => {\n      if (wrapperStream) {\n        wrapperStream.error(error);\n      } else {\n        return reject(error);\n      }\n    });\n\n    stream.on('end', () => {\n      if (wrapperStream) {\n        while (chunks.length) {\n          wrapperStream.write(chunks.shift()!);\n        }\n\n        wrapperStream.end();\n      } else {\n        return resolve(reducer(chunks));\n      }\n    });\n  });\n}\n\n/**\n * Helper to create a readable stream from an existing T.\n */\nexport function toStream<T>(t: T, reducer: Reducer<T>): ReadableStream<T> {\n  const stream = newWriteableStream<T>(reducer);\n\n  stream.end(t);\n\n  return stream;\n}\n\n/**\n * Helper to convert a T into a Readable<T>.\n */\nexport function toReadable<T>(t: T): Readable<T> {\n  let consumed = false;\n\n  return {\n    read: () => {\n      if (consumed) {\n        return null;\n      }\n\n      consumed = true;\n\n      return t;\n    }\n  };\n}\n\n/**\n * Helper to transform a readable stream into another stream.\n */\nexport function transform<Original, Transformed>(stream: ReadableStreamEvents<Original>, transformer: ITransformer<Original, Transformed>, reducer: Reducer<Transformed>): ReadableStream<Transformed> {\n  const target = newWriteableStream<Transformed>(reducer);\n\n  stream.on('data', data => target.write(transformer.data(data)));\n  stream.on('end', () => target.end());\n  stream.on('error', error => target.error(transformer.error ? transformer.error(error) : error));\n\n  return target;\n}\n"]}