{"version":3,"sources":["common/encoding-service.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;kFAckF;AAUlF,OAAO,EAAC,MAAM,EAAC,MAAM,cAAc,CAAC;AAEpC,OAAO,EAAC,YAAY,EAAE,oBAAoB,EAAE,0BAA0B,EAAC,MAAM,UAAU,CAAC;AACxF,OAAO,EAAC,OAAO,EAAe,OAAO,EAA+B,aAAa,EAAC,MAAM,aAAa,CAAC;AACtG,OAAO,EAAqB,QAAQ,EAAE,cAAc,EAAC,MAAM,UAAU,CAAC;AActE,MAAM,WAAW,gBAAgB;IAC/B,QAAQ,EAAE,MAAM,CAAA;IAChB,MAAM,EAAE,OAAO,CAAA;CAChB;AAED,MAAM,WAAW,gBAAgB;IAC/B,QAAQ,CAAC,EAAE,MAAM,CAAA;IACjB,WAAW,CAAC,EAAE,OAAO,CAAA;CACtB;AAED,MAAM,WAAW,mBAAmB;IAClC,aAAa,CAAC,EAAE,OAAO,CAAC;IACxB,4BAA4B,CAAC,EAAE,MAAM,CAAC;IAEtC,iBAAiB,CAAC,gBAAgB,EAAE,MAAM,GAAG,SAAS,GAAG,OAAO,CAAC,MAAM,CAAC,CAAC;CAC1E;AAED,MAAM,WAAW,kBAAkB;IACjC,MAAM,EAAE,cAAc,CAAC,MAAM,CAAC,CAAC;IAC/B,QAAQ,EAAE,gBAAgB,CAAC;CAC5B;AAED,qBACa,eAAe;IAE1B,MAAM,CAAC,KAAK,EAAE,MAAM,EAAE,OAAO,CAAC,EAAE,gBAAgB,GAAG,YAAY;IAW/D,MAAM,CAAC,KAAK,EAAE,YAAY,EAAE,QAAQ,CAAC,EAAE,MAAM,GAAG,MAAM;IAMtD,MAAM,CAAC,QAAQ,EAAE,MAAM,GAAG,OAAO;IAKjC,eAAe,CAAC,QAAQ,CAAC,EAAE,MAAM,GAAG,MAAM;IAOpC,kBAAkB,CAAC,QAAQ,EAAE,MAAM,EAAE,OAAO,EAAE;QAClD,iBAAiB,CAAC,EAAE,OAAO,CAAC;QAC5B,IAAI,EAAE,CAAC,MAAM,EAAE,MAAM,KAAK,OAAO,CAAC,UAAU,CAAC,CAAA;KAC9C,GAAG,OAAO,CAAC,gBAAgB,CAAC;IAwBvB,cAAc,CAAC,IAAI,EAAE,YAAY,EAAE,iBAAiB,CAAC,EAAE,OAAO,GAAG,OAAO,CAAC,gBAAgB,CAAC;IAoEhG,YAAY,CAAC,MAAM,EAAE,0BAA0B,EAAE,OAAO,EAAE,mBAAmB,GAAG,OAAO,CAAC,kBAAkB,CAAC;IAkF3G,YAAY,CAAC,KAAK,EAAE,MAAM,GAAG,QAAQ,CAAC,MAAM,CAAC,EAAE,OAAO,CAAC,EAAE,gBAAgB,GAAG,OAAO,CAAC,YAAY,GAAG,oBAAoB,CAAC;IAExH,YAAY,CAAC,KAAK,CAAC,EAAE,MAAM,GAAG,QAAQ,CAAC,MAAM,CAAC,EAAE,OAAO,CAAC,EAAE,gBAAgB,GAAG,OAAO,CAAC,YAAY,GAAG,oBAAoB,GAAG,SAAS,CAAC;IA2DrI,SAAS,CAAC,6BAA6B,CAAC,MAAM,EAAE,MAAM,EAAE,SAAS,EAAE,MAAM,GAAG,OAAO,aAAa,GAAG,OAAO,OAAO,GAAG,OAAO,OAAO,GAAG,SAAS;cAgC9H,qBAAqB,CAAC,MAAM,EAAE,MAAM,GAAG,OAAO,CAAC,MAAM,GAAG,SAAS,CAAC;CAgBnF","file":"../../src/common/encoding-service.d.ts","sourcesContent":["/********************************************************************************\n * Copyright (C) 2020 TypeFox and others.\n *\n * This program and the accompanying materials are made available under the\n * terms of the Eclipse Public License v. 2.0 which is available at\n * http://www.eclipse.org/legal/epl-2.0.\n *\n * This Source Code may also be made available under the following Secondary\n * Licenses when the conditions for such availability set forth in the Eclipse\n * Public License v. 2.0 are satisfied: GNU General Public License, version 2\n * with the GNU Classpath Exception which is available at\n * https://www.gnu.org/software/classpath/license.html.\n *\n * SPDX-License-Identifier: EPL-2.0 OR GPL-2.0 WITH Classpath-exception-2.0\n ********************************************************************************/\n/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n// based on https://github.com/microsoft/vscode/blob/04c36be045a94fee58e5f8992d3e3fd980294a84/src/vs/workbench/services/textfile/common/encoding.ts\n\n/* eslint-disable no-null/no-null */\n\nimport * as iconv from 'iconv-lite';\nimport {Buffer} from 'safer-buffer';\nimport {injectable} from 'inversify';\nimport {BinaryBuffer, BinaryBufferReadable, BinaryBufferReadableStream} from './buffer';\nimport {UTF16be, UTF16be_BOM, UTF16le, UTF16le_BOM, UTF8, UTF8_BOM, UTF8_with_bom} from './encodings';\nimport {newWriteableStream, Readable, ReadableStream} from './stream';\n\nconst ZERO_BYTE_DETECTION_BUFFER_MAX_LEN = 512;   // number of bytes to look at to decide about a file being binary or not\nconst NO_ENCODING_GUESS_MIN_BYTES = 512;          // when not auto guessing the encoding, small number of bytes are enough\nconst AUTO_ENCODING_GUESS_MIN_BYTES = 512 * 8;    // with auto guessing we want a lot more content to be read for guessing\nconst AUTO_ENCODING_GUESS_MAX_BYTES = 512 * 128;  // set an upper limit for the number of bytes we pass on to jschardet\n\n// we explicitly ignore a specific set of encodings from auto guessing\n// - ASCII: we never want this encoding (most UTF-8 files would happily detect as\n//          ASCII files and then you could not type non-ASCII characters anymore)\n// - UTF-16: we have our own detection logic for UTF-16\n// - UTF-32: we do not support this encoding in VSCode\nconst IGNORE_ENCODINGS = ['ascii', 'utf-16', 'utf-32'];\n\nexport interface ResourceEncoding {\n  encoding: string\n  hasBOM: boolean\n}\n\nexport interface DetectedEncoding {\n  encoding?: string\n  seemsBinary?: boolean\n}\n\nexport interface DecodeStreamOptions {\n  guessEncoding?: boolean;\n  minBytesRequiredForDetection?: number;\n\n  overwriteEncoding(detectedEncoding: string | undefined): Promise<string>;\n}\n\nexport interface DecodeStreamResult {\n  stream: ReadableStream<string>;\n  detected: DetectedEncoding;\n}\n\n@injectable()\nexport class EncodingService {\n\n  encode(value: string, options?: ResourceEncoding): BinaryBuffer {\n    let encoding = options?.encoding;\n    const addBOM = options?.hasBOM;\n    encoding = this.toIconvEncoding(encoding);\n    if (encoding === UTF8 && !addBOM) {\n      return BinaryBuffer.fromString(value);\n    }\n    const buffer = iconv.encode(value, encoding, {addBOM});\n    return BinaryBuffer.wrap(buffer);\n  }\n\n  decode(value: BinaryBuffer, encoding?: string): string {\n    const buffer = Buffer.from(value.buffer);\n    encoding = this.toIconvEncoding(encoding);\n    return iconv.decode(buffer, encoding);\n  }\n\n  exists(encoding: string): boolean {\n    encoding = this.toIconvEncoding(encoding);\n    return iconv.encodingExists(encoding);\n  }\n\n  toIconvEncoding(encoding?: string): string {\n    if (encoding === UTF8_with_bom || !encoding) {\n      return UTF8; // iconv does not distinguish UTF 8 with or without BOM, so we need to help it\n    }\n    return encoding;\n  }\n\n  async toResourceEncoding(encoding: string, options: {\n    overwriteEncoding?: boolean,\n    read: (length: number) => Promise<Uint8Array>\n  }): Promise<ResourceEncoding> {\n    // Some encodings come with a BOM automatically\n    if (encoding === UTF16be || encoding === UTF16le || encoding === UTF8_with_bom) {\n      return {encoding, hasBOM: true};\n    }\n\n    // Ensure that we preserve an existing BOM if found for UTF8\n    // unless we are instructed to overwrite the encoding\n    const overwriteEncoding = options?.overwriteEncoding;\n    if (!overwriteEncoding && encoding === UTF8) {\n      try {\n        // stream here to avoid fetching the whole content on write\n        const buffer = await options.read(UTF8_BOM.length);\n        if (this.detectEncodingByBOMFromBuffer(Buffer.from(buffer), buffer.byteLength) === UTF8_with_bom) {\n          return {encoding, hasBOM: true};\n        }\n      } catch (error) {\n        // ignore - file might not exist\n      }\n    }\n\n    return {encoding, hasBOM: false};\n  }\n\n  async detectEncoding(data: BinaryBuffer, autoGuessEncoding?: boolean): Promise<DetectedEncoding> {\n    const buffer = Buffer.from(data.buffer);\n    const bytesRead = data.byteLength;\n    // Always first check for BOM to find out about encoding\n    let encoding = this.detectEncodingByBOMFromBuffer(buffer, bytesRead);\n\n    // Detect 0 bytes to see if file is binary or UTF-16 LE/BE√è\n    // unless we already know that this file has a UTF-16 encoding\n    let seemsBinary = false;\n    if (encoding !== UTF16be && encoding !== UTF16le && buffer) {\n      let couldBeUTF16LE = true; // e.g. 0xAA 0x00\n      let couldBeUTF16BE = true; // e.g. 0x00 0xAA\n      let containsZeroByte = false;\n\n      // This is a simplified guess to detect UTF-16 BE or LE by just checking if\n      // the first 512 bytes have the 0-byte at a specific location. For UTF-16 LE\n      // this would be the odd byte index and for UTF-16 BE the even one.\n      // Note: this can produce false positives (a binary file that uses a 2-byte\n      // encoding of the same format as UTF-16) and false negatives (a UTF-16 file\n      // that is using 4 bytes to encode a character).\n      for (let i = 0; i < bytesRead && i < ZERO_BYTE_DETECTION_BUFFER_MAX_LEN; i++) {\n        const isEndian = (i % 2 === 1); // assume 2-byte sequences typical for UTF-16\n        const isZeroByte = (buffer.readUInt8(i) === 0);\n\n        if (isZeroByte) {\n          containsZeroByte = true;\n        }\n\n        // UTF-16 LE: expect e.g. 0xAA 0x00\n        if (couldBeUTF16LE && (isEndian && !isZeroByte || !isEndian && isZeroByte)) {\n          couldBeUTF16LE = false;\n        }\n\n        // UTF-16 BE: expect e.g. 0x00 0xAA\n        if (couldBeUTF16BE && (isEndian && isZeroByte || !isEndian && !isZeroByte)) {\n          couldBeUTF16BE = false;\n        }\n\n        // Return if this is neither UTF16-LE nor UTF16-BE and thus treat as binary\n        if (isZeroByte && !couldBeUTF16LE && !couldBeUTF16BE) {\n          break;\n        }\n      }\n\n      // Handle case of 0-byte included\n      if (containsZeroByte) {\n        if (couldBeUTF16LE) {\n          encoding = UTF16le;\n        } else if (couldBeUTF16BE) {\n          encoding = UTF16be;\n        } else {\n          seemsBinary = true;\n        }\n      }\n    }\n\n    // Auto guess encoding if configured\n    if (autoGuessEncoding && !seemsBinary && !encoding && buffer) {\n      const guessedEncoding = await this.guessEncodingByBuffer(buffer.slice(0, bytesRead));\n      return {\n        seemsBinary: false,\n        encoding: guessedEncoding\n      };\n    }\n\n    return {seemsBinary, encoding};\n  }\n\n  decodeStream(source: BinaryBufferReadableStream, options: DecodeStreamOptions): Promise<DecodeStreamResult> {\n    const minBytesRequiredForDetection = options.minBytesRequiredForDetection ?? options.guessEncoding ? AUTO_ENCODING_GUESS_MIN_BYTES : NO_ENCODING_GUESS_MIN_BYTES;\n\n    return new Promise<DecodeStreamResult>((resolve, reject) => {\n      const target = newWriteableStream<string>(strings => strings.join(''));\n\n      const bufferedChunks: BinaryBuffer[] = [];\n      let bytesBuffered = 0;\n\n      let decoder: iconv.DecoderStream | undefined = undefined;\n\n      const createDecoder = async () => {\n        try {\n\n          // detect encoding from buffer\n          const detected = await this.detectEncoding(BinaryBuffer.concat(bufferedChunks), options.guessEncoding);\n\n          // ensure to respect overwrite of encoding\n          detected.encoding = await options.overwriteEncoding(detected.encoding);\n\n          // decode and write buffered content\n          decoder = iconv.getDecoder(this.toIconvEncoding(detected.encoding));\n          const decoded = decoder.write(Buffer.from(BinaryBuffer.concat(bufferedChunks).buffer));\n          target.write(decoded);\n\n          bufferedChunks.length = 0;\n          bytesBuffered = 0;\n\n          // signal to the outside our detected encoding and final decoder stream\n          resolve({\n            stream: target,\n            detected\n          });\n        } catch (error) {\n          reject(error);\n        }\n      };\n\n      // Stream error: forward to target\n      source.on('error', error => target.error(error));\n\n      // Stream data\n      source.on('data', async chunk => {\n\n        // if the decoder is ready, we just write directly\n        if (decoder) {\n          target.write(decoder.write(Buffer.from(chunk.buffer)));\n        } else {\n          bufferedChunks.push(chunk);\n          bytesBuffered += chunk.byteLength;\n\n          // buffered enough data for encoding detection, create stream\n          if (bytesBuffered >= minBytesRequiredForDetection) {\n\n            // pause stream here until the decoder is ready\n            source.pause();\n\n            await createDecoder();\n\n            // resume stream now that decoder is ready but\n            // outside of this stack to reduce recursion\n            setTimeout(() => source.resume());\n          }\n        }\n      });\n\n      // Stream end\n      source.on('end', async () => {\n\n        // we were still waiting for data to do the encoding\n        // detection. thus, wrap up starting the stream even\n        // without all the data to get things going\n        if (!decoder) {\n          await createDecoder();\n        }\n\n        // end the target with the remainders of the decoder\n        target.end(decoder?.end());\n      });\n    });\n  }\n\n  encodeStream(value: string | Readable<string>, options?: ResourceEncoding): Promise<BinaryBuffer | BinaryBufferReadable>\n\n  encodeStream(value?: string | Readable<string>, options?: ResourceEncoding): Promise<BinaryBuffer | BinaryBufferReadable | undefined>;\n\n  async encodeStream(value: string | Readable<string> | undefined, options?: ResourceEncoding): Promise<BinaryBuffer | BinaryBufferReadable | undefined> {\n    let encoding = options?.encoding;\n    const addBOM = options?.hasBOM;\n    encoding = this.toIconvEncoding(encoding);\n    if (encoding === UTF8 && !addBOM) {\n      return value === undefined ? undefined : typeof value === 'string' ?\n          BinaryBuffer.fromString(value) : BinaryBufferReadable.fromReadable(value);\n    }\n\n    value = value || '';\n    const readable = typeof value === 'string' ? Readable.fromString(value) : value;\n    const encoder = iconv.getEncoder(encoding, {addBOM});\n\n    let bytesWritten = false;\n    let done = false;\n\n    return {\n      read(): BinaryBuffer | null {\n        if (done) {\n          return null;\n        }\n\n        const chunk = readable.read();\n        if (typeof chunk !== 'string') {\n          done = true;\n\n          // If we are instructed to add a BOM but we detect that no\n          // bytes have been written, we must ensure to return the BOM\n          // ourselves so that we comply with the contract.\n          if (!bytesWritten && addBOM) {\n            switch (encoding) {\n              case UTF8:\n              case UTF8_with_bom:\n                return BinaryBuffer.wrap(Uint8Array.from(UTF8_BOM));\n              case UTF16be:\n                return BinaryBuffer.wrap(Uint8Array.from(UTF16be_BOM));\n              case UTF16le:\n                return BinaryBuffer.wrap(Uint8Array.from(UTF16le_BOM));\n            }\n          }\n\n          const leftovers = encoder.end();\n          if (leftovers && leftovers.length > 0) {\n            bytesWritten = true;\n            return BinaryBuffer.wrap(leftovers);\n          }\n\n          return null;\n        }\n\n        bytesWritten = true;\n\n        return BinaryBuffer.wrap(encoder.write(chunk));\n      }\n    };\n  }\n\n  protected detectEncodingByBOMFromBuffer(buffer: Buffer, bytesRead: number): typeof UTF8_with_bom | typeof UTF16le | typeof UTF16be | undefined {\n    if (!buffer || bytesRead < UTF16be_BOM.length) {\n      return undefined;\n    }\n\n    const b0 = buffer.readUInt8(0);\n    const b1 = buffer.readUInt8(1);\n\n    // UTF-16 BE\n    if (b0 === UTF16be_BOM[0] && b1 === UTF16be_BOM[1]) {\n      return UTF16be;\n    }\n\n    // UTF-16 LE\n    if (b0 === UTF16le_BOM[0] && b1 === UTF16le_BOM[1]) {\n      return UTF16le;\n    }\n\n    if (bytesRead < UTF8_BOM.length) {\n      return undefined;\n    }\n\n    const b2 = buffer.readUInt8(2);\n\n    // UTF-8\n    if (b0 === UTF8_BOM[0] && b1 === UTF8_BOM[1] && b2 === UTF8_BOM[2]) {\n      return UTF8_with_bom;\n    }\n\n    return undefined;\n  }\n\n  protected async guessEncodingByBuffer(buffer: Buffer): Promise<string | undefined> {\n    const jschardet = await import('jschardet');\n\n    const guessed = jschardet.detect(buffer.slice(0, AUTO_ENCODING_GUESS_MAX_BYTES)); // ensure to limit buffer for guessing due to https://github.com/aadsm/jschardet/issues/53\n    if (!guessed || !guessed.encoding) {\n      return undefined;\n    }\n\n    const enc = guessed.encoding.toLowerCase();\n    if (0 <= IGNORE_ENCODINGS.indexOf(enc)) {\n      return undefined; // see comment above why we ignore some encodings\n    }\n\n    return this.toIconvEncoding(guessed.encoding);\n  }\n\n}\n"]}